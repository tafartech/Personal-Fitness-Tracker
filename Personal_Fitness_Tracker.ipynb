{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOD7gAH48oSv2+DRQOQkkbH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tafartech/Personal-Fitness-Tracker/blob/main/Personal_Fitness_Tracker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rarfile"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uElChUO3DCj2",
        "outputId": "c9581cef-799e-4285-bc01-16ac45b1dee8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rarfile\n",
            "  Downloading rarfile-4.2-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: rarfile\n",
            "Successfully installed rarfile-4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GPU set up**"
      ],
      "metadata": {
        "id": "jhIT8LYsFHbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Check if GPU is available\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"GPU is available. Using {torch.cuda.get_device_name(0)}.\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU is not available. Using CPU.\")\n",
        "\n",
        "# Display device information\n",
        "print(f\"Current device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZV7yQZtaD-uz",
        "outputId": "2624392b-287b-4018-f7c1-332a13d67633"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available. Using Tesla T4.\n",
            "Current device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download the HMDB51 dataset.\n",
        "1. Extract the dataset.\n",
        "2. Preprocess the data: Convert videos to frames, resize them, and organize them for annotation."
      ],
      "metadata": {
        "id": "Acm1K53iE2Bm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import rarfile\n",
        "import cv2\n",
        "\n",
        "# Step 1: Download HMDB51 dataset\n",
        "dataset_url = \"https://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/hmdb51_org.rar\"\n",
        "dataset_path = \"hmdb51_org.rar\"\n",
        "\n",
        "def download_dataset(url, path):\n",
        "    response = requests.get(url, stream=True)\n",
        "    with open(path, 'wb') as f:\n",
        "        for chunk in response.iter_content(chunk_size=1024):\n",
        "            if chunk:\n",
        "                f.write(chunk)\n",
        "    print(f\"Downloaded {path}\")\n",
        "\n",
        "download_dataset(dataset_url, dataset_path)\n",
        "\n",
        "# Step 2: Extract the dataset\n",
        "extracted_folder = \"hmdb51\"\n",
        "\n",
        "def extract_dataset(path, folder):\n",
        "    if not os.path.exists(folder):\n",
        "        os.makedirs(folder)\n",
        "    with rarfile.RarFile(path) as rar_ref:\n",
        "        rar_ref.extractall(folder)\n",
        "    print(f\"Extracted to {folder}\")\n",
        "\n",
        "extract_dataset(dataset_path, extracted_folder)\n",
        "\n",
        "# Step 3: Preprocess the data\n",
        "def video_to_frames(video_path, output_folder):\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    count = 0\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frame = cv2.resize(frame, (224, 224))\n",
        "        frame_filename = os.path.join(output_folder, f\"frame_{count:05d}.jpg\")\n",
        "        cv2.imwrite(frame_filename, frame)\n",
        "        count += 1\n",
        "    cap.release()\n",
        "    print(f\"Converted {video_path} to frames in {output_folder}\")\n",
        "\n",
        "# Convert all videos in the dataset\n",
        "for root, dirs, files in os.walk(extracted_folder):\n",
        "    for file in files:\n",
        "        if file.endswith(\".avi\"):\n",
        "            video_path = os.path.join(root, file)\n",
        "            output_folder = os.path.join(root, file.split('.')[0])\n",
        "            video_to_frames(video_path, output_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3UCc4dFDGG7",
        "outputId": "13266740-3312-4748-81f6-bd4dc26866fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded hmdb51_org.rar\n",
            "Extracted to hmdb51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Install LabelImg:**\n",
        "I need to install LabelImg in the environment:"
      ],
      "metadata": {
        "id": "HnkfgIXfFiDQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install labelImg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hXnyzZfgEioj",
        "outputId": "1f3e20d1-ff10-4af5-821a-19ca0b1d9b48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting labelImg\n",
            "  Downloading labelImg-1.8.6.tar.gz (247 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.7/247.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyqt5 (from labelImg)\n",
            "  Downloading PyQt5-5.15.10-cp37-abi3-manylinux_2_17_x86_64.whl (8.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from labelImg) (4.9.4)\n",
            "Collecting PyQt5-sip<13,>=12.13 (from pyqt5->labelImg)\n",
            "  Downloading PyQt5_sip-12.13.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.whl (338 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m338.1/338.1 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyQt5-Qt5>=5.15.2 (from pyqt5->labelImg)\n",
            "  Downloading PyQt5_Qt5-5.15.14-py3-none-manylinux2014_x86_64.whl (60.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.5/60.5 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: labelImg\n",
            "  Building wheel for labelImg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for labelImg: filename=labelImg-1.8.6-py2.py3-none-any.whl size=261519 sha256=b3662faafe4e4be59310cf4fb040cd278275a2f4c381c741b40287875d46a197\n",
            "  Stored in directory: /root/.cache/pip/wheels/d9/f0/1e/74c509495458cad13a0fda23fe605e643177625cf2b5c17b34\n",
            "Successfully built labelImg\n",
            "Installing collected packages: PyQt5-Qt5, PyQt5-sip, pyqt5, labelImg\n",
            "Successfully installed PyQt5-Qt5-5.15.14 PyQt5-sip-12.13.0 labelImg-1.8.6 pyqt5-5.15.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the frames from the dataset\n",
        "Load the frames and launch LabelImg for annotation:"
      ],
      "metadata": {
        "id": "CFW4E4nMFsKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "# Path to the frames directory\n",
        "frames_dir = \"hmdb51\"\n",
        "\n",
        "# Install LabelImg if not already installed\n",
        "!pip install labelImg\n",
        "\n",
        "# Launch LabelImg for annotation\n",
        "subprocess.run([\"labelImg\", frames_dir])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMwdUUYtFXZd",
        "outputId": "fdcc6ea5-104f-4fb8-d2b7-b11f92dd4c57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: labelImg in /usr/local/lib/python3.10/dist-packages (1.8.6)\n",
            "Requirement already satisfied: pyqt5 in /usr/local/lib/python3.10/dist-packages (from labelImg) (5.15.10)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from labelImg) (4.9.4)\n",
            "Requirement already satisfied: PyQt5-sip<13,>=12.13 in /usr/local/lib/python3.10/dist-packages (from pyqt5->labelImg) (12.13.0)\n",
            "Requirement already satisfied: PyQt5-Qt5>=5.15.2 in /usr/local/lib/python3.10/dist-packages (from pyqt5->labelImg) (5.15.14)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CompletedProcess(args=['labelImg', 'hmdb51'], returncode=-6)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Organize the Dataset\n",
        "I will start by organizing the frames into training and validation directories. Here is a script to move the frames into the appropriate directories:"
      ],
      "metadata": {
        "id": "-ndFGmjsJKmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import rarfile\n",
        "\n",
        "# Define paths\n",
        "dataset_path = \"/content/hmdb51_org.rar\"\n",
        "extracted_folder = \"/content/hmdb51\"\n",
        "\n",
        "# Function to extract RAR file\n",
        "def extract_dataset(rar_path, folder):\n",
        "    with rarfile.RarFile(rar_path) as rf:\n",
        "        rf.extractall(folder)\n",
        "    print(f\"Extracted to {folder}\")\n",
        "\n",
        "# Extract the dataset\n",
        "extract_dataset(dataset_path, extracted_folder)\n",
        "\n",
        "# Verify the extracted structure\n",
        "extracted_subfolders = os.listdir(extracted_folder)\n",
        "print(f\"Subfolders in extracted dataset: {extracted_subfolders}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7lZPf67U8it",
        "outputId": "8b964358-6013-4c9d-d0d1-f4963dede603"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted to /content/hmdb51\n",
            "Subfolders in extracted dataset: ['somersault.rar', 'dive.rar', 'shoot_bow.rar', 'push.rar', 'smoke.rar', 'punch.rar', 'drink.rar', 'shoot_ball.rar', 'sword_exercise.rar', 'pullup.rar', 'run.rar', 'pour.rar', 'talk.rar', 'turn.rar', 'wave.rar', 'sword.rar', 'handstand.rar', 'fall_floor.rar', 'hug.rar', 'eat.rar', 'jump.rar', 'smile.rar', 'climb_stairs.rar', 'hit.rar', 'shoot_gun.rar', 'walk.rar', 'swing_baseball.rar', 'clap.rar', 'cartwheel.rar', 'chew.rar', 'brush_hair.rar', 'ride_horse.rar', 'laugh.rar', 'golf.rar', 'situp.rar', 'pushup.rar', 'kick.rar', 'climb.rar', 'draw_sword.rar', 'dribble.rar', 'catch.rar', 'pick.rar', 'flic_flac.rar', 'stand.rar', 'ride_bike.rar', 'throw.rar', 'shake_hands.rar', 'fencing.rar', 'kick_ball.rar', 'kiss.rar', 'sit.rar']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Organize the Dataset into Train and Validation Sets"
      ],
      "metadata": {
        "id": "bf3nilKPYGzI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import rarfile\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define paths\n",
        "dataset_base_path = \"/content/yolo_hmdb51\"\n",
        "extracted_folder = \"/content/hmdb51\"\n",
        "\n",
        "# Create the directory structure\n",
        "os.makedirs(os.path.join(dataset_base_path, \"images/train\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(dataset_base_path, \"images/val\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(dataset_base_path, \"labels/train\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(dataset_base_path, \"labels/val\"), exist_ok=True)\n",
        "\n",
        "# Function to extract images from activity RAR files\n",
        "def extract_activity_files(activity_rar_path, destination_folder):\n",
        "    with rarfile.RarFile(activity_rar_path) as rf:\n",
        "        rf.extractall(destination_folder)\n",
        "\n",
        "# Extract and organize dataset\n",
        "train_ratio = 0.8\n",
        "\n",
        "for activity_rar in os.listdir(extracted_folder):\n",
        "    activity_name = os.path.splitext(activity_rar)[0]\n",
        "    temp_extract_folder = os.path.join(extracted_folder, activity_name)\n",
        "    os.makedirs(temp_extract_folder, exist_ok=True)\n",
        "\n",
        "    # Extract images\n",
        "    extract_activity_files(os.path.join(extracted_folder, activity_rar), temp_extract_folder)\n",
        "\n",
        "    # Get all image files\n",
        "    all_files = [f for f in os.listdir(temp_extract_folder) if f.endswith('.jpg')]\n",
        "    num_train = int(len(all_files) * train_ratio)\n",
        "\n",
        "    train_files = all_files[:num_train]\n",
        "    val_files = all_files[num_train:]\n",
        "\n",
        "    # Move files to train and val directories\n",
        "    for file in train_files:\n",
        "        shutil.move(os.path.join(temp_extract_folder, file), os.path.join(dataset_base_path, \"images/train\", f\"{activity_name}_{file}\"))\n",
        "\n",
        "    for file in val_files:\n",
        "        shutil.move(os.path.join(temp_extract_folder, file), os.path.join(dataset_base_path, \"images/val\", f\"{activity_name}_{file}\"))\n",
        "\n",
        "    # Remove temporary extraction folder\n",
        "    shutil.rmtree(temp_extract_folder)\n",
        "\n",
        "print(\"Dataset organized into train and validation sets.\")"
      ],
      "metadata": {
        "id": "62hVPst9WzyC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a447c62a-63ad-4dde-a719-c67850270ca1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset organized into train and validation sets.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# Function to extract frames from video files\n",
        "def extract_frames(video_file, dest_folder, frame_rate=1):\n",
        "    import cv2\n",
        "    if not os.path.exists(dest_folder):\n",
        "        os.makedirs(dest_folder)\n",
        "    cap = cv2.VideoCapture(video_file)\n",
        "    count = 0\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        if count % frame_rate == 0:\n",
        "            frame_filename = os.path.join(dest_folder, f\"{os.path.basename(video_file).split('.')[0]}_frame{count}.jpg\")\n",
        "            cv2.imwrite(frame_filename, frame)\n",
        "        count += 1\n",
        "    cap.release()\n",
        "\n",
        "# Define paths\n",
        "dataset_dir = '/content/hmdb51'\n",
        "extracted_folder = '/content/hmdb51_extracted'\n",
        "dataset_base_path = \"/content/yolo_hmdb51\"\n",
        "image_train_path = os.path.join(dataset_base_path, \"images/train\")\n",
        "image_val_path = os.path.join(dataset_base_path, \"images/val\")\n",
        "label_train_path = os.path.join(dataset_base_path, \"labels/train\")\n",
        "label_val_path = os.path.join(dataset_base_path, \"labels/val\")\n",
        "\n",
        "# Create directories if they don't exist\n",
        "os.makedirs(image_train_path, exist_ok=True)\n",
        "os.makedirs(image_val_path, exist_ok=True)\n",
        "os.makedirs(label_train_path, exist_ok=True)\n",
        "os.makedirs(label_val_path, exist_ok=True)\n",
        "\n",
        "# Check for videos in the extracted dataset\n",
        "for subfolder in os.listdir(dataset_dir):\n",
        "    subfolder_path = os.path.join(dataset_dir, subfolder)\n",
        "    if os.path.isdir(subfolder_path):\n",
        "        for file in os.listdir(subfolder_path):\n",
        "            if file.endswith(\".avi\"):  # Assuming videos are in .avi format\n",
        "                video_file_path = os.path.join(subfolder_path, file)\n",
        "                # Extract frames to a temporary folder\n",
        "                temp_folder = '/content/temp_frames'\n",
        "                extract_frames(video_file_path, temp_folder)\n",
        "                # Split frames into train and val\n",
        "                all_frames = os.listdir(temp_folder)\n",
        "                random.shuffle(all_frames)\n",
        "                split_index = int(0.8 * len(all_frames))\n",
        "                train_frames = all_frames[:split_index]\n",
        "                val_frames = all_frames[split_index:]\n",
        "                # Move frames to respective directories\n",
        "                for frame in train_frames:\n",
        "                    shutil.move(os.path.join(temp_folder, frame), os.path.join(image_train_path, frame))\n",
        "                for frame in val_frames:\n",
        "                    shutil.move(os.path.join(temp_folder, frame), os.path.join(image_val_path, frame))\n",
        "                # Clean up temp folder\n",
        "                shutil.rmtree(temp_folder)\n",
        "\n",
        "print(\"Frames organized into training and validation sets.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhNn2y9hZUXY",
        "outputId": "1765bdc3-1e85-40fa-e1a8-8bb8215e3c43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frames organized into training and validation sets.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert Annotations\n",
        "Now, I'll convert the annotations from VOC to YOLO format. Adjust the script to reflect the correct paths:"
      ],
      "metadata": {
        "id": "2Y-oUEDwJrdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import cv2\n",
        "\n",
        "# Function to convert VOC to YOLO format\n",
        "def convert_voc_to_yolo(xml_file, output_file, img_width, img_height):\n",
        "    tree = ET.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    with open(output_file, 'w') as f:\n",
        "        for obj in root.findall('object'):\n",
        "            class_name = obj.find('name').text  # Change this to your class name handling logic\n",
        "            class_id = 0  # Assuming a single class; update accordingly\n",
        "            xmlbox = obj.find('bndbox')\n",
        "            b = (float(xmlbox.find('xmin').text), float(xmlbox.find('xmax').text),\n",
        "                 float(xmlbox.find('ymin').text), float(xmlbox.find('ymax').text))\n",
        "            bb = ((b[0] + b[1]) / 2.0 / img_width, (b[2] + b[3]) / 2.0 / img_height,\n",
        "                  (b[1] - b[0]) / img_width, (b[3] - b[2]) / img_height)\n",
        "            f.write(f\"{class_id} {' '.join([str(a) for a in bb])}\\n\")\n",
        "\n",
        "# Process each file in the dataset\n",
        "for phase in ['train', 'val']:\n",
        "    image_dir = f\"{output_dir}/images/{phase}\"\n",
        "    label_dir = f\"{output_dir}/labels/{phase}\"\n",
        "    for img_file in os.listdir(image_dir):\n",
        "        if img_file.endswith(\".jpg\"):\n",
        "            img_path = os.path.join(image_dir, img_file)\n",
        "            xml_file = img_path.replace(\".jpg\", \".xml\")  # Adjust path to match annotation location\n",
        "            yolo_file = os.path.join(label_dir, img_file.replace(\".jpg\", \".txt\"))\n",
        "\n",
        "            # Read the image to get its dimensions\n",
        "            img = cv2.imread(img_path)\n",
        "            height, width, _ = img.shape\n",
        "\n",
        "            # Convert and save the annotation\n",
        "            convert_voc_to_yolo(xml_file, yolo_file, width, height)"
      ],
      "metadata": {
        "id": "ZZxHtToSJRwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZexMpU7Ye8he"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uS9ra-bKe8yW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}